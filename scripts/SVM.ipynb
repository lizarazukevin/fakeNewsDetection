{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from quadprog_wrapper import solve_quadprog\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Used nrows to specify how many rows to use from the imported file\n",
    "# Only used 1000 due to memory issues\n",
    "train_data = pd.read_csv('train.csv', nrows=1000)\n",
    "test_data = pd.read_csv('test.csv', nrows=1000)\n",
    "\n",
    "# Preprocess data\n",
    "train_data = cleanData_1(train_data)\n",
    "test_data = cleanData_1(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vocabulary to hold words\n",
    "vocabulary = defaultdict(int)\n",
    "for text in train_data['text']:\n",
    "    for word in text:\n",
    "        vocabulary[word] += 1\n",
    "\n",
    "# Assign numerical IDs to words in vocabulary\n",
    "word_ids = {}\n",
    "for i, word in enumerate(vocabulary.keys()):\n",
    "    word_ids[word] = i\n",
    "\n",
    "# Convert text data to numerical features\n",
    "train_X = np.zeros((len(train_data), len(word_ids)))\n",
    "for i, text in enumerate(train_data['text']):\n",
    "    for word in text:\n",
    "        if word in word_ids:\n",
    "            train_X[i, word_ids[word]] += 1\n",
    "# Convert for testing data as well\n",
    "test_X = np.zeros((len(test_data), len(word_ids)))\n",
    "for i, text in enumerate(test_data['text']):\n",
    "    for word in text:\n",
    "        if word in word_ids:\n",
    "            test_X[i, word_ids[word]] += 1\n",
    "\n",
    "# Convert label data to numerical labels\n",
    "train_label = np.where(train_data['label'] == 'real', 1, -1)\n",
    "test_label = np.where(test_data['label'] == 'real', 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of SVM loosely based off HW 3 Linear Kernel model\n",
    "class SVM:\n",
    "    def __init__(self):\n",
    "        self.params = {'kernel': 'linear', 'C': 1.0}\n",
    "\n",
    "    def rbf_kernel(self, row_data, col_data, sigma):\n",
    "        \"\"\"\n",
    "        Compute the Gram matrix between row_data and col_data for the Gaussian radial-basis function (RBF) kernel.\n",
    "\n",
    "        :param row_data: ndarray of shape (2, m), where each column is a data example\n",
    "        :type row_data: ndarray\n",
    "        :param col_data: ndarray of shape (2, n), where each column is a data example\n",
    "        :type col_data: ndarray\n",
    "        :param sigma: scalar quantity that scales the Euclidean distance inside the exponent of the RBF value\n",
    "        :type sigma: float\n",
    "        :return: a matrix whose (i, j) entry is the kernel value between row_data[:, i] and col_data[:, j]\n",
    "        :rtype: ndarray\n",
    "        \"\"\"\n",
    "        #############################################\n",
    "        # TODO: Insert your code below to implement the RBF kernel.\n",
    "        # This computation should take around 1--3 lines of code if you use matrix operations.\n",
    "        # One hint on how to accomplish this is the fact that for vectors x, y:\n",
    "        # (x - y).dot(x - y) = x.dot(x) + y.dot(y) - 2 * x.dot(y)\n",
    "        #############################################\n",
    "\n",
    "        return np.exp((1 / (-2 * sigma * sigma)) * ((np.sum(pow(row_data, 2), axis=0, keepdims=True).T + np.sum(\n",
    "            pow(col_data, 2), axis=0, keepdims=True)) - (2 * (row_data.T.dot(col_data)))))\n",
    "\n",
    "    def linear_kernel(self, row_data, col_data):\n",
    "        \"\"\"\n",
    "        Compute the Gram matrix between row_data and col_data for the linear kernel.\n",
    "        :param row_data: ndarray of shape (2, m), where each column is a data example\n",
    "        :type row_data: ndarray\n",
    "        :param col_data: ndarray of shape (2, n), where each column is a data example\n",
    "        :type col_data: ndarray\n",
    "        :return: a matrix whose (i, j) entry is the kernel value between row_data[:, i] and col_data[:, j]\n",
    "        :rtype: ndarray\n",
    "        \"\"\"\n",
    "        return row_data.T.dot(col_data)\n",
    "    # Training\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: Data (title, text, etc.)\n",
    "        :param y: Labels\n",
    "        :return: the model (model)\n",
    "        \"\"\"\n",
    "        if self.params['kernel'] == 'rbf':\n",
    "            gram_matrix = self.rbf_kernel(X, X, self.params['sigma'])\n",
    "        else:\n",
    "            gram_matrix = self.linear_kernel(X, X)\n",
    "        # symmetrize to help correct minor numerical errors\n",
    "        gram_matrix = (gram_matrix + gram_matrix.T) / 2\n",
    "\n",
    "        n = gram_matrix.shape[0]\n",
    "\n",
    "        # Setting up the inputs to the quadratic programming solver that solves:\n",
    "        # minimize      0.5 x^T (hessian) x - (weights)^T x\n",
    "        # subject to    (eq_coeffs) x = (eq_constants)\n",
    "        #   and         (lower_bounds) <= x <= (upper_bounds)\n",
    "        hessian = np.outer(y, y) * gram_matrix\n",
    "        weights = np.ones(n)\n",
    "\n",
    "        eq_coeffs = np.zeros((1, n))\n",
    "        eq_coeffs[0, :] = y\n",
    "        eq_constants = np.zeros(1)\n",
    "\n",
    "        lower_bounds = np.zeros(n)\n",
    "        upper_bounds = self.params['C']\n",
    "\n",
    "        # Call quadratic program with provided inputs.\n",
    "        alphas = solve_quadprog(hessian, weights, eq_coeffs, eq_constants, None,\n",
    "                                None, lower_bounds, upper_bounds)\n",
    "\n",
    "        self.model = dict()\n",
    "\n",
    "        # process optimized alphas to only store support vectors and alphas that have nonnegligible support\n",
    "        tolerance = 1e-6\n",
    "        sv_indices = alphas > tolerance\n",
    "        self.model['support_vectors'] = X[:, sv_indices]\n",
    "        self.model['alphas'] = alphas[sv_indices]\n",
    "        self.model['params'] = self.params  # store the kernel type and parameters\n",
    "        self.model['sv_labels'] = y[sv_indices]\n",
    "\n",
    "        # find all alphas that represent points on the decision margin\n",
    "        margin_alphas = np.logical_and(\n",
    "            alphas > tolerance, alphas < self.params['C'] - tolerance)\n",
    "\n",
    "        # compute the bias value\n",
    "        if np.any(margin_alphas):\n",
    "            self.model['bias'] = np.mean(y[margin_alphas].T - (alphas * y).T.dot(gram_matrix[:, margin_alphas]))\n",
    "        else:\n",
    "            # there were no support vectors on the margin (this should only happen due to numerical errors)\n",
    "            self.model['bias'] = 0\n",
    "\n",
    "    # Prediction\n",
    "    def predict(self, X):\n",
    "        gram_matrix = self.linear_kernel(X, self.model['support_vectors'])\n",
    "        scores = gram_matrix.dot(\n",
    "            self.model['alphas'] * self.model['sv_labels']) + self.model['bias']\n",
    "        scores = scores.ravel()\n",
    "        labels = 2 * (scores > 0) - 1  # threshold and map to {-1, 1}\n",
    "\n",
    "        return labels, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "svm = SVM()\n",
    "svm.train(np.array(list(train_X)).T, train_label)\n",
    "\n",
    "# Test model\n",
    "predictions = svm.predict(np.array(list(test_X)).T)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = np.mean(predictions == test_label)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
